## TisEval
we propose the general toxicity
and bias evaluation framework TisEval, the first
comprehensive and systematic evaluation of Chi-
nese LLMs from the perspectives of toxicity and
bias. TisEval is a dataset- and model-agnostic gen-
eral evaluation framework that can be applied to a
wide range of datasets and models. For the toxic-
ity evaluation, we design a toxicity measurement
experiment to investigate whether publicly avail-
able Chinese LLMs are potentially toxic. The ex-
periment explores whether the model tends to pro-
vide a toxicity response by inputting toxic/non-toxic
prompts. 
![捕获](https://github.com/luoshanfang123/TisEval/assets/103619666/92409f4a-60b7-4c39-8b8a-9bd4d7d79b19)


## Note

BELLE 评估需要将 BELLE 仓库放在工作目录下，具体可查看 `chat.py #21`。
https://github.com/LianjiaTech/BELLE

EVA
https://github.com/thu-coai/EVA

pangu-alpha
https://github.com/huawei-noah/Pretrained-Language-Model
